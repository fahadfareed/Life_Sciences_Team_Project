
@Article{Shelhamer2016,
  author   = {Evan Shelhamer and Jonathan Long and Trevor Darrell},
  title    = {Fully Convolutional Networks for Semantic Segmentation},
  journal  = {PAMI},
  year     = {2016},
  comment  = {- shift and stitch: shift coarse (zero-padded?) input and interlace resulting window to a result; wavelet community= à trous algorithm: network changed to do no downsampling with coarse (convolution?) filters
- bilinear interpolation
- deconvolution -> with activation functions: nonlinear upsampling possible; "fast and effective"
-learning through upsampling with skip layer fusion -> more effective and efficient than shift-and-stitch},
  file     = {Shelhamer et al. 2016:long_shelhamer_fcn.pdf:PDF},
  keywords = {not learnable, fixed filter, learnable, transposed convolution},
  url      = {http://arxiv.org/abs/1605.06211},
}

@Article{Weigert2018,
  author   = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and Müller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Siân and Rocha-Martins, Mauricio and Segovia-Miranda, Fabián and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Loic and Jug, Florian and Myers, Eugene W.},
  title    = {Content-aware image restoration: pushing the limits of fluorescence microscopy},
  journal  = {Nature Methods},
  year     = {2018},
  volume   = {15},
  number   = {12},
  pages    = {1090--1097},
  month    = dec,
  issn     = {1548-7105},
  abstract = {Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME.},
  comment  = {- only useful as link to other papers
- hints to U-Nets [34] [36] and deconvolution [17-19]},
  file     = {Weigert et al. 2018:s41592-018-0216-7.pdf:PDF},
  refid    = {Weigert2018},
  url      = {https://doi.org/10.1038/s41592-018-0216-7},
}

@Article{Guo2018,
  author   = {Guo, Yanming and Liu, Yu and Georgiou, Theodoros and Lew, Michael S.},
  title    = {A review of semantic segmentation using deep neural networks},
  journal  = {International Journal of Multimedia Information Retrieval},
  year     = {2018},
  volume   = {7},
  number   = {2},
  pages    = {87--93},
  month    = {Jun},
  issn     = {2192-662X},
  abstract = {During the long history of computer vision, one of the grand challenges has been semantic segmentation which is the ability to segment an unknown image into different parts and objects (e.g., beach, ocean, sun, dog, swimmer). Furthermore, segmentation is even deeper than object recognition because recognition is not necessary for segmentation. Specifically, humans can perform image segmentation without even knowing what the objects are (for example, in satellite imagery or medical X-ray scans, there may be several objects which are unknown, but they can still be segmented within the image typically for further investigation). Performing segmentation without knowing the exact identity of all objects in the scene is an important part of our visual understanding process which can give us a powerful model to understand the world and also be used to improve or augment existing computer vision techniques. Herein this work, we review the field of semantic segmentation as pertaining to deep convolutional neural networks. We provide comprehensive coverage of the top approaches and summarize the strengths, weaknesses and major challenges.},
  comment  = {hints to papers:
- [21] region-based classification -> pixel prediction
- [22] RCNN actual architecture for 21; [37] Faster RCNN
- [30, 31] multiscale conventional grouping (?)
- [32] "coarse to fine image pyramid", [33] convolutional feature masking (?)
- [34] spatial pyramid pooling (?)
- [38-40] promising: pixel to pixel mapping
- [42] deep deconvolutional network
- [43, 44] atrous convolution -> bilinear interpolation -> Conditional Random Field (CRF) inference (?), [46] dense CRFs as Recurrent neural networks RNN
- [48] pyramid scene parsing network (?)},
  day      = {01},
  doi      = {10.1007/s13735-017-0141-z},
  file     = {Guo et al. 2018:Guo2018_Article_AReviewOfSemanticSegmentationU.pdf:PDF},
  url      = {https://doi.org/10.1007/s13735-017-0141-z},
}

@Article{Garcia-Garcia2017,
  author        = {Alberto Garcia{-}Garcia and Sergio Orts{-}Escolano and Sergiu Oprea and Victor Villena{-}Martinez and Jos{\'{e}} Garc{\'{\i}}a Rodr{\'{\i}}guez},
  title         = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
  journal       = {CoRR},
  year          = {2017},
  volume        = {abs/1704.06857},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/Garcia-GarciaOO17},
  eprint        = {1704.06857},
  file          = {Garcia-Garcia et al. 2017:1704.06857.pdf:PDF},
  timestamp     = {Mon, 13 Aug 2018 16:46:10 +0200},
  url           = {http://arxiv.org/abs/1704.06857},
}

@Article{Zhu2017,
  author   = {X. X. {Zhu} and D. {Tuia} and L. {Mou} and G. {Xia} and L. {Zhang} and F. {Xu} and F. {Fraundorfer}},
  title    = {Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources},
  journal  = {IEEE Geoscience and Remote Sensing Magazine},
  year     = {2017},
  volume   = {5},
  number   = {4},
  pages    = {8-36},
  month    = {Dec},
  issn     = {2168-6831},
  comment  = {- [128] shows promising
- look for "upsampling"},
  doi      = {10.1109/MGRS.2017.2762307},
  file     = {Zhu et al. 2017:08113128.pdf:PDF},
  keywords = {remote sensing;climate change;remote-sensing data analysis;machine-learning techniques;data-intensive science;looming paradigm shift;Machine learning;Remote sensing;Feature extraction;Hyperspectral imaging;Computer vision;Tutorials;Remote sensing},
}

@Article{McCann2017,
  author   = {M. T. {McCann} and K. H. {Jin} and M. {Unser}},
  title    = {Convolutional Neural Networks for Inverse Problems in Imaging: A Review},
  journal  = {IEEE Signal Processing Magazine},
  year     = {2017},
  volume   = {34},
  number   = {6},
  pages    = {85-95},
  month    = {Nov},
  issn     = {1053-5888},
  comment  = {- look for upsampling},
  doi      = {10.1109/MSP.2017.2739299},
  file     = {MCCann et al. 2017:08103129.pdf:PDF},
  keywords = {image classification;image denoising;image reconstruction;image resolution;image segmentation;medical image processing;neural nets;convolutional neural networks;inverse problems;deep CNN;object classification;segmentation tasks;image denoising;image deconvolution;image superresolution;medical image reconstruction;sparsity-based techniques;compressed sensing;Inverse problems;Image reconstruction;Computed tomography;Noise reduction;Linear programming;Image segmentation;Image resolution;Neural networks},
}

@InProceedings{Hariharan2015,
  author    = {Hariharan, Bharath and Arbelaez, Pablo and Girshick, Ross and Malik, Jitendra},
  title     = {Hypercolumns for Object Segmentation and Fine-Grained Localization},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2015},
  month     = {June},
  comment   = {- 2 related work might contain more useful upsampling references
- they only use bilinear interpolation, but they don't upsample the image, they upsample feature maps
- provide formula for bilinear interpolation},
  file      = {Hariharan2015:Hariharan_Hypercolumns_for_Object_2015_CVPR_paper.pdf:PDF},
}

@InProceedings{Dai2015,
  author    = {Dai, Jifeng and He, Kaiming and Sun, Jian},
  title     = {Convolutional Feature Masking for Joint Object and Stuff Segmentation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2015},
  month     = {June},
  comment   = {- spatial pyramid pooling: masks feature maps, fixes length of features
- objects vs. stuff like sky, grass
- no upsampling even mentioned (they use a classifier and then whatnot},
  file      = {Dai2015:Dai_Convolutional_Feature_Masking_2015_CVPR_paper.pdf:PDF},
}

@InProceedings{Caesar2016,
  author    = {Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},
  title     = {Region-Based Semantic Segmentation with End-to-End Training},
  booktitle = {Computer Vision -- ECCV 2016},
  year      = {2016},
  editor    = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  pages     = {381--397},
  address   = {Cham},
  publisher = {Springer International Publishing},
  abstract  = {We propose a novel method for semantic segmentation, the task of labeling each pixel in an image with a semantic class. Our method combines the advantages of the two main competing paradigms. Methods based on region classification offer proper spatial support for appearance measurements, but typically operate in two separate stages, none of which targets pixel labeling performance at the end of the pipeline. More recent fully convolutional methods are capable of end-to-end training for the final pixel labeling, but resort to fixed patches as spatial support. We show how to modify modern region-based approaches to enable end-to-end training for semantic segmentation. This is achieved via a differentiable region-to-pixel layer and a differentiable free-form Region-of-Interest pooling layer. Our method improves the state-of-the-art in terms of class-average accuracy with {\$}{\$}64.0{\backslash},{\backslash}{\%}{\$}{\$}64.0{\%}on SIFT Flow and {\$}{\$}49.9{\backslash},{\backslash}{\%}{\$}{\$}49.9{\%}on PASCAL Context, and is particularly accurate at object boundaries.},
  comment   = {- region-to-pixel-prediction (directly maps prediction to draw area)
- rare classes lead to exploding gradients and numerical problems
- semantic segmentation doesn't neet upsampling, but putting labels on pixels basically},
  isbn      = {978-3-319-46448-0},
}

@InProceedings{Noh2015,
  author        = {Noh, Hyeonwoo and Hong, Seunghoon and Han, Bohyung},
  title         = {Learning Deconvolution Network for Semantic Segmentation},
  booktitle     = {The IEEE International Conference on Computer Vision (ICCV)},
  year          = {2015},
  month         = {December},
  __markedentry = {[Nr.12:]},
  comment       = {- [1, 19] might be interesting to read: FCNs
- explains Shelhamer in section 2
- comparison FCN and deep deconv},
  file          = {Noh2015:Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf:PDF},
}

@Article{Chen2018,
  author        = {L. {Chen} and G. {Papandreou} and I. {Kokkinos} and K. {Murphy} and A. L. {Yuille}},
  title         = {DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year          = {2018},
  volume        = {40},
  number        = {4},
  pages         = {834-848},
  month         = {April},
  issn          = {0162-8828},
  __markedentry = {[Nr.12:6]},
  doi           = {10.1109/TPAMI.2017.2699184},
  file          = {Chen2018:07913730.pdf:PDF},
  keywords      = {convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes;highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models;Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context;Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields},
}
